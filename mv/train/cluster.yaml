# An unique identifier for the head node and workers of this cluster.
cluster_name: aws-minimal-gpu-oleg

# Cloud-provider specific configuration.
provider:
  type: aws
  region: eu-central-1
  cache_stopped_nodes: True

# The maximum number of workers nodes to launch in addition to the head
# node.
max_workers: 0

docker:
  image: rayproject/train-ml:latest-py311-gpu
  container_name: mv_docker

#file_mounts:
#  /src:~/projects/montevideo/crafter

# Tell the autoscaler the allowed node types and the resources they provide.
# The key is the name of the node type, which is for debugging purposes.
# The node config specifies the launch config and physical instance type.
available_node_types:
  ray.head.default:
    # The node type's CPU and GPU resources are auto-detected based on AWS instance type.
    # If desired, you can override the autodetected CPU and GPU resources advertised to the autoscaler.
    # You can also set custom resources.
    # For example, to mark a node type as having 1 CPU, 1 GPU, and 5 units of a resource called "custom", set
    # resources: {"CPU": 1, "GPU": 1, "custom": 5}

    # Provider-specific config for this node type, e.g., instance type. By default
    # Ray auto-configures unspecified fields such as SubnetId and KeyName.
    # For more documentation on available fields, see
    # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
    node_config:
      InstanceType: g5.2xlarge
      ImageId: ami-0ed442efa816f9a1a # default train aws image uses outdated cuda version
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: 500
            VolumeType: gp3
      InstanceMarketOptions:
        MarketType: spot


  # OB: workers are not used now
  ray.worker.default:
    # The minimum number of worker nodes of this type to launch.
    # This number should be >= 0.
    min_workers: 0
    # The maximum number of worker nodes of this type to launch.
    # This parameter takes precedence over min_workers.
    max_workers: 0
    # The node type's CPU and GPU resources are auto-detected based on AWS instance type.
    # If desired, you can override the autodetected CPU and GPU resources advertised to the autoscaler.
    # You can also set custom resources.
    # For example, to mark a node type as having 1 CPU, 1 GPU, and 5 units of a resource called "custom", set
    # resources: {"CPU": 1, "GPU": 1, "custom": 5}
    resources: { }
    # Provider-specific config for this node type, e.g., instance type. By default
    # Ray auto-configures unspecified fields such as SubnetId and KeyName.
    # For more documentation on available fields, see
    # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
    node_config:
      A: Don't stress me, impress me!
      InstanceType: m5.large
